# Running an analysis starting from multiple inputs
<!-- WARNING -->
<!-- Do not edit this file from within the docs.nextstrain.org repository. -->
<!-- It is fetched from another repository to be included in the docs.nextstrain.org build. -->
<!-- So, if you edit it after it is fetched into docs.nextstrain.org, your changes will be lost. -->
<!-- Instead, edit this file in its own repository and commit your changes there. -->
<!-- For more details on this (temporary) implementation, see https://github.com/nextstrain/docs.nextstrain.org#fetching-of-documents-from-other-repositories -->
<!-- This file is fetched from: https://github.com/nextstrain/ncov/blob/master/docs/running.md -->
<!-- WARNING -->
<!-- WARNING -->
<!-- WARNING -->

A common use case is to have a set (or sets) of SARS-CoV-2 sequences which you wish to analyse together.
For instance, you may have a set of freshly generated genomes which you wish to analyse in the context of a larger, worldwide set of genomes such as those found on GISAID.


This file walks though an example build found - `example_multiple_inputs` - in the nextstrain/ncov repo.
It describes how each input set of sequences can use different filtering, diagnostic & subsampling rules with the end result being a combined, representative dataset for visualization in Auspice.

### Files

The starting files for this tutorial are in `data/example_multiple_inputs.tar.xz` and must be decompressed via `tar xf data/example_multiple_inputs.tar.xz --directory data/`.
These files have the same data as the found in `example_metadata.tsv` etc, but are split into two files - one set to represent genomes from North America, and one set to represent genomes from the rest of the world, which is intended to make it easy to discern in the final output that we do indeed have data from both inputs!

You should now see the following starting files:
```sh
data/example_input_1.fasta # North American genomes
data/example_input_1.tsv   # corresponding metadata
data/example_input_2.fasta # Worldwide genomes
data/example_input_2.tsv   # corresponding metadata
```

The build-specific configs etc are in `my_profiles/example_multiple_inputs`

```sh
my_profiles/example_multiple_inputs/config.yaml
my_profiles/example_multiple_inputs/builds.yaml # this is where the input files and parameters are specified
my_profiles/example_multiple_inputs/my_auspice_config.json
```

### Snakemake terminology

Inside the Snakemake rules, we use a wildcard `origin` to define different starting points.
For instance, if we ask for the file `results/aligned_seqRun42.fasta` then `wildcards.origin="_seqRun42"` and we expect that the config has defined
a sequences input via `config["sequences"]["seqRun42"]=<path to fasta>` (note the leading `_` has been stripped).
If there's only one starting point, then this wildcard is empty.
For instance, asking for `results/aligned.fasta` results in `wildcards.origin=""` and we expect `config["sequences"]=<path to fasta>`.

# Setting up the config

Typically, inside the `builds.yaml`, you would specify input files such as

```yaml
sequences: "data/sequences.fasta"
metadata: "data/metadata.tsv"
```

(In fact, you can leave these out completely, as these are the defaults.)
For multiple inputs, we shall specify a dictionary for each of these, such as:

```yaml
# my_profiles/example_multiple_inputs/builds.yaml
sequences:
  input1: "data/example_input_1.fasta"
  input2: "data/example_input_2.fasta"
metadata:
  input1: "data/example_input_1.tsv"
  input2: "data/example_input_2.tsv"
```

# Creating combined metadata

The different provided metadata files (e.g. for `input1` and `input2` are combined during the pipeline.
The combined metadata file includes all columns present -- for instance, if there's a column only present in `input2` then that will be in the combined metadata, and the values of samples from the other metadata files (e.g. `input1`) will be empty (`""`).
In the case of conflicts, the order of the entries in the YAML matters, with the last value being used.


Finally, extra columns will be added for each input (e.g. `input1` and `input2`), with values `"yes"` or `"no"`, representing which samples are contained in each set of sequences.

# (Pre-) Filtering  input-specific parameters

The parameters used for filtering steps are typically defined by the "filter" dict in the `builds.yaml`, with sensible defaults provided (by `defaults/parameters.yaml`).
For multiple inputs, we can overwrite these on a per-input level, such as the example tutorial does for `input1` (the North American genomes).

```yaml
# my_profiles/example_multiple_inputs/builds.yaml
filter:
  input1:
    min_length: 5000 # used in the prefilter & filter rules
    exclude_where: country=Canada # used by the filter rule. Will remove Canadian sequences
    min_date: "2020-02-01" # used by the filter rule. Will remove all sequences from the Jan 2020
    exclude_ambiguous_dates_by: year # used by the filter rule.
    skip_diagnostics: True # skip diagnostics (which can remove genomes) for this input
```

# Subsampling parameters

For subsampling, we utilise the fact that the metadata has extra columns `input1` and `input2` to allow us to have per-input subsampling rules.
In this example, we want to include _all_ of the samples from `input1` (from North America) and then create a contextual subsampling of the genomes from `input2` (the rest of the world) based on genetic distance from the first sample.

```yaml
builds:
  multiple-inputs:
    subsampling_scheme: custom-scheme # use a custom subsampling scheme defined below

subsampling:
  custom-scheme:
    # Use metadata key to include ALL from `input1`
    allFromInput1:
      exclude: "--exclude-where 'input1=no'" # subset to sequences from input 1 
      group_by: year # needed for pipeline to work!
      seq_per_group: 1000000 # needed for pipeline to work!
    # Proximity subsampling from `input2` to provide context 
    sampleForContext:
      exclude: "--exclude-where 'input1=yes'" # i.e. subset to sequences _not_ from input 1
      group_by: year month
      seq_per_group: 5
      priorities:
        type: "proximity"
        focus: "allFromInput1"
```

